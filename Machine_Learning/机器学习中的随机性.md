![](https://github.com/LiuChuang0059/large_file/blob/master/pic/zz341.jpg)

-----


### 1. 机器学习算法中的 随机性

#### 1. 数据收集中的随机性

不同的数据，机器学习算法会构建不同的模型 ， 数据本身就是一种随机性

#### 2. 数据输入顺序 （Observation Order）

数据输入到模型的顺序会影响内部的决策。一些算法（神经网络）尤其明显敏感。在每次训练迭代之前打乱训练数据的顺序是一个比较好的方法。

#### 3. 算法的随机性

算法会初始化到一个随机的状态：例如神经网络中的初始化权重
> Votes that end in a draw (and other internal decisions) during training in a deterministic method may rely on randomness to resolve.



#### 4. 采样的随机性
训练数据太多，需要随机的采集子样本

#### 5. 重采样的随机性 -- resampling

当我们测试一个算法，使用随机分割（train/test）数据集或者 k-fold 交叉验证的方法随机 k 份分割


----

### 2. Random Seeds and Reproducible Results -- 随机种子和可重复结果


我们通过使用完全相同的 code data 和 **随机数序列** 实现可重复性。随机数通过内部的随机数生成器生成，是由一个简单的函数生成一系列的数字，这个函数是**固定的**

随机数的生成函数固定，如果使用同样的其实点-- **seed number**，就会生成相同的随机数字。

所以，我们可以获得可重复性结果通过固定 **生成器的种子**

----

### 3. 解决算法不确定性的策略

#### 1. 减少不确定性
随机重复和随机再重启 --andom repeats or random restarts.

尝试多次 run 这个模型 gather a population of performance measures

类似于 k-fold 建立多个模型，只要数据还能代表问题。

或者重复评估过程 n 次

#### 2. 报告不确定性
> Never report the performance of your machine learning algorithm with a single number.


已经有 a population of performance measures， 根据统计学，结果应该呈现高斯分布的

最好报告一个表现的 **平均值和标准差**以及 最好和最坏的数据


---

### 4. final model 的选择

使用不同的 随机数序列能够有不同的模型，那我们应该选择一个在 validation 中表现最好的模型吗（精度最高）？

> validation set 完全独立，

**不应该**， 因为这高度依赖 validation 数据集的数据质量，不能因为一小部分数据来优化这个随机数


> Sometimes your application domain makes you care more.
In this situation, I would tell you to build an ensemble of models, each trained with a different random number seed.
Use a simple voting ensemble. Each model makes a prediction and the mean of all predictions is reported as the final prediction.
Make the ensemble as big as you need to. I think 10, 30 or 100 are nice round numbers.
Maybe keep adding new models until the predictions become stable. For example, continue until the variance of the predictions tightens up on some holdout set.





# 参考

https://machinelearningmastery.com/randomness-in-machine-learning/































