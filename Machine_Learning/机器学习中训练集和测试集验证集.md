![](https://github.com/LiuChuang0059/large_file/blob/master/pic/h8ybl.jpg)

-----

### 1.样本充足

> 如果给定的**样本充足**，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分为训练集（training set）、验证集（validation set）和测试集（testing set）。训练集用来训练模型，验证集用于模型的选择，而测试集用于最终对学习方法评估。在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。由于验证集有足够多的数据，用它对模型进行选择也是有效的。

---

### 2. 样本不足


----

### 3. 三个数据集的 作用


![](https://i.loli.net/2019/08/28/dYsZar9DneoRcyq.png)


1. 训练集 ： 调整模型的参数 ： weights

2. validation set ：

* 不是调整参数，主要是为了防止过拟合。 例如如果训练集的训练精度不断增加，而测试集的精度在减少，overfitting，停止训练
> To make sure you dont overfit the network you need to input the validation dataset to the network and check if the error is within some range. Because the validation set is not being using directly to adjust the weights of the netowork, therefore a good error for the validation and also the test set indicates that the network predicts well for the train set examples, also it is expected to perform well when new example are presented to the network which was not used in the training process.

* model selection ：
> 通过训练集学习到参数，再计算验证集上的error，再选择一个在验证集上error最小的模型，最后再在测试集上估计模型的泛化误差。

3. 测试集： 测试模型，评价模型的泛化能力。在测试集上得到的结果和以后新数据的结果差不多

----



### 4. Validation set 选择

Validation ： 确保模型有很好的泛化能力

主要有两个作用

* 更好的调节模型的**超参数**
> 注意超参数不是模型的参数。 超参数是那些不能通过常规训练学习到的参数， 代表模型的高级特性
> 例如： 随机森林中， 我们需要决定使用多少 决策树以及 使用多少特征分割一个节点。 这些都是超参数


![](https://i.loli.net/2019/08/28/yHjBkdWP65INAoK.png)

* 作为一个中间测试集
> 对于机器学习模型，当我们在调参数的时候，永远不要看测试集。  因为测试集是最接近我们模型在真实数据上面表现。不应该使用测试集中的信息


既然我们不能接触测试集，我们需要从训练集中提取一些数据。这就产生了一个问题。我们拥有的训练数据越多，我们的参数估计就越好，但是我们保留的用于验证的数据越多，我们就能够更好地调优超参数。
考虑到这一权衡，我们有几种可用的验证方法。

#### 1. Hold-Out Validation

![](https://i.loli.net/2019/08/28/BsCX1ANnqeFDPdh.png)

对于训练集 随机采样分割成 训练和验证，常用的是 80%和20%

**Pros**
* 完全独立的数据——从训练集中分离出来的数据成为一个完全独立的单元。我们从来没有碰过它，因此我们得到了一个用于中间测试的整洁的集合。

* 只分割一次，节省算力

**Cons**

* 不能很好的泛化， 分割数据的不同， 模型误差相差也会很大


#### 2. K-Fold Cross Validation

![](https://i.loli.net/2019/08/28/79Apg8lhBWxRarw.png)

将数据分成 k 份， 每次留一份用来作为 validation set。最后预测的准确率使用所有 K 次的平均值


**Pros**

* 泛化能力较好

* 这种方法遍历整个训练集，因此在分割数据集时不存在选择偏差


**Cons**

* 模型寻来呢时间较长， 每次都要训练 K 次


#### 3. LOOCV — A Special Case of Cross Validation

“Leave One Out” Cross-Validation

上面 的 K -fold 的特例， 这里 K = 数据集的大小， 只留一个作为测试


#### 4. Bootstrap Resampling 重采样


1. 选择样本的大小

2. while 目前样本的大小 < 选择的大小:

	 1. 从数据集中随机选择

	 2. 加入到样本（原数据集中不删除）
![](https://i.loli.net/2019/08/28/ZdDO1k8vtLuGUNF.png)

可以用来计算人口统计， 也可以用来评估机器学习模型的表现
> The bootstrap is a widely applicable and extremely powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method.

这需要在一部分样本上训练模型， 在其他的样本上（不包括之前的）进行评估。 没有包含在给定样本中的这些样本称为袋外样本(out-of-bag samples，简称OOB)。


1. 选择一些要运行的 bootstrap 样本

2. 选择样本的大小

3. 对于每一个 bootstrap 样本 ：

	1. 置换采样的方法获取到设定的样本大小

	2. 在样本上训练模型

	3. 在 OOB 上评估模型




bootstrap方法的一个有用特性是，估计的结果样本通常形成高斯分布。除了以集中趋势总结这种分布外，还可以给出方差的度量，如标准差和标准误差。此外，一个置信区间可以计算出来，并用于约束所提出的估计。这在展示机器学习模型的效果。




**Bootstrap 的配置**

1. 样本大小

通常选择和原始数据一样大， 但是这样一些数据会出现重复

2. 重复

重复的次数必须足够大，以确保能够在样本上计算出有意义的统计数据，例如平均值、标准差和标准误差。

至少要重复20到30次。使用较小的值将进一步增加对估计值样本计算的统计量的方差。

理想情况下，在给定时间资源的情况下，估计值的样本应该尽可能大，重复成百上千次。


**Bootstap 举例**

假设我们有一个数据集
```
[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]
```

我们进行 Bootstrap  采样，获得数据样本

```

sample = [0.2, 0.1, 0.2, 0.6]
```

其他的就是 oob， 所以对于一个机器学习模型

```python
train = [0.2, 0.1, 0.2, 0.6]
test = [0.3, 0.4, 0.5]
model = fit(train)
statistic = evaluate(model, test)

```

上面是一次重复， 我们要做 30 或者更多次的重复, 得到一个模型表现列表， 最后进行统计分析。


```python
statistic = [...]
```


**Sklearn 中 Bootstap实现**

```python

# scikit-learn bootstrap
from sklearn.utils import resample
# data sample
data = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]
# prepare bootstrap sample
boot = resample(data, replace=True, n_samples=4, random_state=1)
print('Bootstrap Sample: %s' % boot)
# out of bag observations
oob = [x for x in data if x not in boot]
print('OOB Sample: %s' % oob)

```


----


# 参考

1. https://blog.csdn.net/u010167269/article/details/51340070

2. 《统计学习方法》 --- 李航

3. [Use of Cross Validation in Machine Learning](https://medium.com/x8-the-ai-community/use-of-cross-validation-in-machine-learning-f3b80ad813e6)

4. [An Introduction to the Bootstrap Method](https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60)

5. [A Gentle Introduction to the Bootstrap Method](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)