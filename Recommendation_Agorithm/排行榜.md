# 1. Ranking

* Popularity is the obvious baseline + Many other features can be added


* Quality of ranking measured using metrics--指标衡量
 >  但是难以用这些指标 优化机器学习模型
  *  Normalized Discounted Cumulative Gain
  *  Mean Reciprocal Rank (MRR)
  *  Fraction of Concordant Pairs (FCP) 
  

* Approaches
 * Point wise --- 逐点的
  * Ranking function minimizes loss function defined on individual relevance judgment
  * Logistic regression, SVM, GBDT
  
 * Pairwise
  * Loss function is defined on pair-wise preferences
  * minimize number of inversions in ranking-----两两一对，目标就是减少 反序的数量
  * RankSVM, RankBoost, RankNet, FRank...
 
 * Listwise
  * Indirect loss function 
   * RankCosine: similarity between ranking list and ground truthas loss function
   * ListNet: KL-divergence as loss function by defining aprobability distribution
   * Problem: optimization of listwise loss function may not optimizeIR metrics
 
  * Directly optimizing IR metric (difficult since they arenot differentiable)
   − Genetic Programming or Simulated Annealing

− LambdaMart weights pairwise errors in RankNet by IR metric

− Gradient descent on smoothed version of objective function (e.g. CLiMF or TFMAP)

− SVM-MAP relaxes MAP metric by adding to SVM constraints

− AdaRank uses boosting to optimize NDCG
